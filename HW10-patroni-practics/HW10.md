# Развертывание HA кластера
*В большинстве мест намеренно скрыт вывод команд, т.к. он не несет никакой смысловой нагрузки*
## Инициализация yc (токен заменен)
    nick@orlov:~$ yc init
    Welcome! This command will take you through the configuration process.
    Please go to https://oauth.yandex.ru/authorize?response_type=token&client_id=1a6990aa636648e9b2ef855fa7bec2fb in order to obtain OAuth token.
     Please enter OAuth token: <TOKEN>
    Please select cloud to use: 
     [1] autotest (id = b1grn83eh5o68cc6s7om)
     [2] cloud (id = b1gjgvbi6rpq79p8c5jk)
     [3] cloud-norlovarenadataio (id = b1grnn2rpdptbl6mrsbg)
    Please enter your numeric choice: 3
    Your current cloud has been set to 'cloud-norlovarenadataio' (id = b1grnn2rpdptbl6mrsbg).
    Please choose folder to use:
     [1] default (id = b1g3brh0uludko815092)
     [2] Create a new folder
    Please enter your numeric choice: 1
    Your current folder has been set to 'default' (id = b1g3brh0uludko815092).
    Do you want to configure a default Compute zone? [Y/n] Y
    Which zone do you want to use as a profile default?
     [1] ru-central1-a
     [2] ru-central1-b
     [3] ru-central1-d
     [4] Don't set default zone
    Please enter your numeric choice: 1
    Your profile default Compute zone has been set to 'ru-central1-a'.
    nick@orlov:~$ yc config list
    token: <TOKEN>
    cloud-id: b1grnn2rpdptbl6mrsbg
    folder-id: b1g3brh0uludko815092
    compute-default-zone: ru-central1-a
## Создаем сетевую инфраструктуру:
    nick@orlov:~$ yc vpc network create \
        --name otus-net \
        --description "otus-net" \
    
    yc vpc network list
    id: enpbroi520q10911d02b
    folder_id: b1g3brh0uludko815092
    created_at: "2024-12-06T04:18:22Z"
    name: otus-net
    description: otus-net
    default_security_group_id: enp35dtqe4dc43hn5qqr
    
    +----------------------+----------+
    |          ID          |   NAME   |
    +----------------------+----------+
    | enpbroi520q10911d02b | otus-net |
    | enppng51tgert7b5lhne | default  |
    +----------------------+----------+
    
    nick@orlov:~$ yc vpc subnet create \
        --name otus-subnet \
        --range 10.0.0.0/24 \
        --network-name otus-net \
        --description "otus-subnet" \
    
    yc vpc subnet list
    id: e9bhuk5i23rvkrd7l9jc
    folder_id: b1g3brh0uludko815092
    created_at: "2024-12-06T04:18:41Z"
    name: otus-subnet
    description: otus-subnet
    network_id: enpbroi520q10911d02b
    zone_id: ru-central1-a
    v4_cidr_blocks:
      - 10.0.0.0/24
    
    +----------------------+-----------------------+----------------------+----------------+---------------+-----------------+
    |          ID          |         NAME          |      NETWORK ID      | ROUTE TABLE ID |     ZONE      |      RANGE      |
    +----------------------+-----------------------+----------------------+----------------+---------------+-----------------+
    | b0cbp1piodkpfr9g0spc | default-ru-central1-c | enppng51tgert7b5lhne |                | ru-central1-c | [10.130.0.0/24] |
    | e2ldob2lgrcfmg3dsm0l | default-ru-central1-b | enppng51tgert7b5lhne |                | ru-central1-b | [10.129.0.0/24] |
    | e9bhuk5i23rvkrd7l9jc | otus-subnet           | enpbroi520q10911d02b |                | ru-central1-a | [10.0.0.0/24]   |
    | e9bjh1hjamllat5of7od | default-ru-central1-a | enppng51tgert7b5lhne |                | ru-central1-a | [10.128.0.0/24] |
    | fl86fjje8phuann4en35 | default-ru-central1-d | enppng51tgert7b5lhne |                | ru-central1-d | [10.131.0.0/24] |
    +----------------------+-----------------------+----------------------+----------------+---------------+-----------------+
    
    nick@orlov:~$ yc dns zone create --name otus-dns \
    --zone staging. \
    --private-visibility network-ids=enp4vcfcnhmq2eliqbps
    
    yc dns zone list
    id: dns972lmtfks1tor4i7e
    folder_id: b1g3brh0uludko815092
    created_at: "2024-12-06T04:18:55.327Z"
    name: otus-dns
    zone: staging.
    private_visibility: {}
    
    +----------------------+----------+----------+------------+-------------+
    |          ID          |   NAME   |   ZONE   | VISIBILITY | DESCRIPTION |
    +----------------------+----------+----------+------------+-------------+
    | dns972lmtfks1tor4i7e | otus-dns | staging. |            |             |
    +----------------------+----------+----------+------------+-------------+
## Развернем 3 ВМ для ETCD:
    for i in {1..3}; do yc compute instance create --name etcd$i --hostname etcd$i --cores 2 --memory 2 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub & done;
    # part output are hidden
    Command 'asd' not found, but there are 23 similar ones.
    [1]   Done                    yc compute instance create --name etcd$i --hostname etcd$i --cores 2 --memory 2 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub
    [2]-  Done                    yc compute instance create --name etcd$i --hostname etcd$i --cores 2 --memory 2 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub
    [3]+  Done                    yc compute instance create --name etcd$i --hostname etcd$i --cores 2 --memory 2 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub
## Развернем 3 ВМ для PostgreSQL:
    for i in {1..3}; do yc compute instance create --name pgsql$i --hostname pgsql$i --cores 2 --memory 4 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub & done;
    # part output are hidden
    [1]   Done                    yc compute instance create --name pgsql$i --hostname pgsql$i --cores 2 --memory 4 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub
    [2]-  Done                    yc compute instance create --name pgsql$i --hostname pgsql$i --cores 2 --memory 4 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub
    [3]+  Done                    yc compute instance create --name pgsql$i --hostname pgsql$i --cores 2 --memory 4 --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 --ssh-key ~/.ssh/id_ed25519.pub
## Развернем ВМ для HAProxy:
    nick@orlov:~$ yc compute instance create \
        --name haproxy \
        --hostname haproxy \
        --cores 2 \
        --memory 2 \
        --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2004-lts \
        --network-interface subnet-name=otus-subnet,nat-ip-version=ipv4 \
        --ssh-key ~/.ssh/id_ed25519.pub
    # part output are hidden
    done (36s)
    id: fhmt0npi26sp17cf6931
## Список развернутых ВМ:
    nick@orlov:~$ yc compute instance list
    +----------------------+---------+---------------+---------+----------------+-------------+
    |          ID          |  NAME   |    ZONE ID    | STATUS  |  EXTERNAL IP   | INTERNAL IP |
    +----------------------+---------+---------------+---------+----------------+-------------+
    | fhm86qcv5jr986pbfnjl | etcd3   | ru-central1-a | RUNNING | 89.169.149.83  | 10.0.0.6    |
    | fhmeqsvn5kiqgquivt6d | etcd2   | ru-central1-a | RUNNING | 89.169.145.118 | 10.0.0.18   |
    | fhmr2s4qavmsdckqst81 | etcd1   | ru-central1-a | RUNNING | 89.169.155.190 | 10.0.0.28   |
    | fhmroum8s07np9uih79a | pgsql1  | ru-central1-a | RUNNING | 51.250.73.134  | 10.0.0.15   |
    | fhmt0npi26sp17cf6931 | haproxy | ru-central1-a | RUNNING | 89.169.152.19  | 10.0.0.5    |
    | fhmt1s2ni8n32q8ggptj | pgsql3  | ru-central1-a | RUNNING | 62.84.112.116  | 10.0.0.38   |
    | fhmubjag8nsrc5u15cg1 | pgsql2  | ru-central1-a | RUNNING | 51.250.2.139   | 10.0.0.22   |
    +----------------------+---------+---------------+---------+----------------+-------------+
## Прописываем хосты в каждой ВМ:
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address <<EOF
    sudo bash -c 'cat >> /etc/hosts <<EOL
    10.0.0.28 etcd1
    10.0.0.18 etcd2
    10.0.0.6 etcd3
    10.0.0.15 pgsql1
    10.0.0.22 pgsql2
    10.0.0.38 pgsql3
    10.0.0.5 haproxy
    EOL
    '
    EOF
    done;
    
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address <<EOF
    sudo bash -c 'cat >> /etc/hosts <<EOL
    10.0.0.28 etcd1
    10.0.0.18 etcd2
    10.0.0.6 etcd3
    10.0.0.15 pgsql1
    10.0.0.22 pgsql2
    10.0.0.38 pgsql3
    10.0.0.5 haproxy
    EOL
    '
    EOF
    done;
    
    vm_ip_address=$(yc compute instance show --name haproxy | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    
    sudo nano /etc/hosts
    
    10.0.0.28 etcd1
    10.0.0.18 etcd2
    10.0.0.6 etcd3
    10.0.0.15 pgsql1
    10.0.0.22 pgsql2
    10.0.0.38 pgsql3
    10.0.0.5 haproxy
    # output hidden
## Установка ETCD на 3 ВМ:
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y && sudo apt install -y etcd' & done;
    # output hidden
    [1]   Done                    vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y && sudo apt install -y etcd'
    [2]-  Done                    vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y && sudo apt install -y etcd'
    [3]+  Done                    vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y && sudo apt install -y etcd'
    nick@orlov:~$ vm_ip_address=$(yc compute instance show --name etcd1 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    Welcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.4.0-200-generic x86_64)
    
     * Documentation:  https://help.ubuntu.com
       * Management:     https://landscape.canonical.com
       * Support:        https://ubuntu.com/pro
    New release '22.04.5 LTS' available.
    Run 'do-release-upgrade' to upgrade to it.
    
    yc-user@etcd1:~$ etcd --version
    etcd Version: 3.2.26
    Git SHA: Not provided (use ./build instead of go build)
    Go Version: go1.13.8
    Go OS/Arch: linux/amd64
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo systemctl stop etcd && systemctl is-enabled etcd && systemctl status etcd' & done;

    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address <<EOF
    sudo bash -c 'cat >> /etc/default/etcd <<EOL
    ETCD_NAME="etcd$i"
    ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
    ETCD_ADVERTISE_CLIENT_URLS="http://etcd$i:2379"
    ETCD_LISTEN_PEER_URLS="http://0.0.0.0:2380"
    ETCD_INITIAL_ADVERTISE_PEER_URLS="http://etcd$i:2380"
    ETCD_INITIAL_CLUSTER_TOKEN="etcd_claster"
    ETCD_INITIAL_CLUSTER="etcd1=http://etcd1:2380,etcd2=http://etcd2:2380,etcd3=http://etcd3:2380"
    ETCD_INITIAL_CLUSTER_STATE="new"
    ETCD_DATA_DIR="/var/lib/etcd"
    ETCD_ENABLE_V2="true"
    EOL
    '
    EOF
    done;
    
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'ETCDCRL_API=2 && echo $ETCDCRL_API' & done;
    
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name etcd$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo systemctl start etcd' & done;
    
    vm_ip_address=$(yc compute instance show --name etcd1 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    # output hidden

    yc-user@etcd1:~$ etcdctl member list
    25d0bfa2dcffa2d7: name=etcd1 peerURLs=http://etcd1:2380 clientURLs=http://etcd1:2379 isLeader=true
    875a9230d9ea0259: name=etcd2 peerURLs=http://etcd2:2380 clientURLs=http://etcd2:2379 isLeader=false
    df0d680875ee2e00: name=etcd3 peerURLs=http://etcd3:2380 clientURLs=http://etcd3:2379 isLeader=false
    yc-user@etcd1:~$ etcdctl cluster-health
    member 25d0bfa2dcffa2d7 is healthy: got healthy result from http://etcd1:2379
    member 875a9230d9ea0259 is healthy: got healthy result from http://etcd2:2379
    member df0d680875ee2e00 is healthy: got healthy result from http://etcd3:2379
    cluster is healthy
## Установка PostgreSQL на 3 ВМ:
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y -q && echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" | sudo tee -a /etc/apt/sources.list.d/pgdg.list && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo apt -y install postgresql-14' & done;
    # output hidden
    [1]   Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y -q && echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" | sudo tee -a /etc/apt/sources.list.d/pgdg.list && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo apt -y install postgresql-14'
    [2]-  Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y -q && echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" | sudo tee -a /etc/apt/sources.list.d/pgdg.list && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo apt -y install postgresql-14'
    [3]+  Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt update && sudo apt upgrade -y -q && echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" | sudo tee -a /etc/apt/sources.list.d/pgdg.list && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo apt -y install postgresql-14'
## Убедимся, что кластера Постгреса стартовали
    nick@orlov:~$ for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'hostname; pg_lsclusters' & done;
    [1] 11049
    [2] 11050
    [3] 11052
    nick@orlov:~$ pgsql3
    Ver Cluster Port Status Owner    Data directory              Log file
    14  main    5432 online postgres /var/lib/postgresql/14/main /var/log/postgresql/postgresql-14-main.log
    pgsql1
    Ver Cluster Port Status Owner    Data directory              Log file
    14  main    5432 online postgres /var/lib/postgresql/14/main /var/log/postgresql/postgresql-14-main.log
    pgsql2
    Ver Cluster Port Status Owner    Data directory              Log file
    14  main    5432 online postgres /var/lib/postgresql/14/main /var/log/postgresql/postgresql-14-main.log
## Установка Patroni на 3 ВМ(pgsql):
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt install -y python3 python3-pip git mc && sudo pip3 install psycopg2-binary && sudo systemctl stop postgresql@14-main && sudo -u postgres pg_dropcluster 14 main && sudo pip3 install patroni[etcd] && sudo ln -s /usr/local/bin/patroni /bin/patroni' & done;
    # output hidden
    [1]   Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt install -y python3 python3-pip git mc && sudo pip3 install psycopg2-binary && sudo systemctl stop postgresql@14-main && sudo -u postgres pg_dropcluster 14 main && sudo pip3 install patroni[etcd] && sudo ln -s /usr/local/bin/patroni /bin/patroni'
    [2]-  Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt install -y python3 python3-pip git mc && sudo pip3 install psycopg2-binary && sudo systemctl stop postgresql@14-main && sudo -u postgres pg_dropcluster 14 main && sudo pip3 install patroni[etcd] && sudo ln -s /usr/local/bin/patroni /bin/patroni'
    [3]+  Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo apt install -y python3 python3-pip git mc && sudo pip3 install psycopg2-binary && sudo systemctl stop postgresql@14-main && sudo -u postgres pg_dropcluster 14 main && sudo pip3 install patroni[etcd] && sudo ln -s /usr/local/bin/patroni /bin/patroni'

    nick@orlov:~$ vm_ip_address=$(yc compute instance show --name pgsql1 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    Welcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.4.0-200-generic x86_64)
    
     * Documentation:  https://help.ubuntu.com
     * Management:     https://landscape.canonical.com
     * Support:        https://ubuntu.com/pro
    New release '22.04.5 LTS' available.
    Run 'do-release-upgrade' to upgrade to it.
    
    yc-user@pgsql1:~$ /usr/local/bin/patroni --version
    patroni 4.0.4
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'cat > temp.cfg << EOF 
    [Unit]
    Description=Runners to orchestrate a high-availability PostgreSQL
    After=syslog.target network.target
    [Service]
    Type=simple
    User=postgres
    Group=postgres
    ExecStart=/usr/local/bin/patroni /etc/patroni.yml
    KillMode=process
    TimeoutSec=30
    Restart=no
    [Install]
    WantedBy=multi-user.target
    EOF
    cat temp.cfg | sudo tee -a /etc/systemd/system/patroni.service
    ' & done;
## На всех нодах необходимо создать папку для хранения файлов и назначить ей нужные права, в нашем случае это /mnt/patroni.
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo systemctl daemon-reload && sudo apt install etcd-client && sudo mkdir /mnt/patroni && sudo chown postgres:postgres /mnt/patroni && sudo chmod 700 /mnt/patroni' & done;
    # output hidden
    [1]   Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo systemctl daemon-reload && sudo apt install etcd-client && sudo mkdir /mnt/patroni && sudo chown postgres:postgres /mnt/patroni && sudo chmod 700 /mnt/patroni'
    [2]-  Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo systemctl daemon-reload && sudo apt install etcd-client && sudo mkdir /mnt/patroni && sudo chown postgres:postgres /mnt/patroni && sudo chmod 700 /mnt/patroni'
    [3]+  Done                    vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'sudo systemctl daemon-reload && sudo apt install etcd-client && sudo mkdir /mnt/patroni && sudo chown postgres:postgres /mnt/patroni && sudo chmod 700 /mnt/patroni'
    for i in {1..3}; do vm_ip_address=$(yc compute instance show --name pgsql$i | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address 'cat > temp2.cfg << EOF 
    scope: patroni
    name: $(hostname)
    restapi:
      listen: $(hostname -I | tr -d " "):8008
      connect_address: $(hostname -I | tr -d " "):8008
    etcd:
      hosts: etcd1:2379,etcd2:2379,etcd3:2379
    bootstrap:
      dcs:
        ttl: 30
        loop_wait: 10
        retry_timeout: 10
        maximum_lag_on_failover: 1048576
        postgresql:
          use_pg_rewind: true
          parameters:
      initdb: 
      - encoding: UTF8
        - data-checksums
        pg_hba: 
        - host replication replicator 10.0.0.0/24 md5
        - host all all 10.0.0.0/24 md5
        users:
          admin:
            password: admin_321
            options:
              - createrole
              - createdb
    postgresql:
        listen: 127.0.0.1, $(hostname -I | tr -d " "):5432
        connect_address: $(hostname -I | tr -d " "):5432
        data_dir: /var/lib/postgresql/14/main
        bin_dir: /usr/lib/postgresql/14/bin
        pgpass: /tmp/pgpass0
        authentication:
          replication:
            username: replicator
            password: rep-pass_321
          superuser:
            username: postgres
            password: postgres
          rewind:  
            username: rewind_user
            password: rewind_password_321
        parameters:
          unix_socket_directories: '.'
    tags:
          nofailover: false
          noloadbalance: false
          clonefrom: false
          nosync: false
    EOF
    cat temp2.cfg | sudo tee -a /etc/patroni.yml
    ' & done;

    vm_ip_address=$(yc compute instance show --name pgsql1 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    sudo systemctl enable patroni && sudo systemctl start patroni 
    sudo patronictl -c /etc/patroni.yml list 
    
    vm_ip_address=$(yc compute instance show --name pgsql2 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    sudo systemctl enable patroni && sudo systemctl start patroni 
    sudo patronictl -c /etc/patroni.yml list 
    
    vm_ip_address=$(yc compute instance show --name pgsql3 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    sudo systemctl enable patroni && sudo systemctl start patroni 
    sudo patronictl -c /etc/patroni.yml list 
    
    yc-user@pgsql3:~$ sudo patronictl -c /etc/patroni.yml list 
    + Cluster: patroni (7445162979816317630) --+----+-----------+
    | Member | Host      | Role    | State     | TL | Lag in MB |
    +--------+-----------+---------+-----------+----+-----------+
    | pgsql1 | 10.0.0.15 | Leader  | running   |  1 |           |
    | pgsql2 | 10.0.0.22 | Replica | streaming |  1 |         0 |
    | pgsql3 | 10.0.0.38 | Replica | streaming |  1 |         0 |
    +--------+-----------+---------+-----------+----+-----------+
## Устанавливаем HAproxy на ноду haproxy:
    vm_ip_address=$(yc compute instance show --name haproxy | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    
    sudo apt-get update && sudo apt-get install -y haproxy
    
## Правим конфиг:
    sudo nano /etc/haproxy/haproxy.cfg
    
    global
            log /dev/log local0
            log /dev/log local1 notice
            chroot /var/lib/haproxy
            stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
            stats timeout 30s
            user haproxy
            group haproxy
            daemon
    
    defaults
            log global
            option tcplog
            option dontlognull
            timeout connect 5000
            timeout client 50000
            timeout server 50000
            errorfile 400 /etc/haproxy/errors/400.http
            errorfile 403 /etc/haproxy/errors/403.http
            errorfile 408 /etc/haproxy/errors/408.http
            errorfile 500 /etc/haproxy/errors/500.http
            errorfile 502 /etc/haproxy/errors/502.http
            errorfile 503 /etc/haproxy/errors/503.http
            errorfile 504 /etc/haproxy/errors/504.http
    
            frontend postgres_frontend
            bind *:5432
            mode tcp
            default_backend postgres_backend
    
            backend postgres_backend
            mode tcp
            balance roundrobin
            option tcp-check
            default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions
            server pgsql1 10.0.0.27:5432 check
            server pgsql2 10.0.0.7:5432 check
            server pgsql3 10.0.0.13:5432 check
    
            listen stats
            bind *:8404
            mode http
            stats enable
            stats uri /stats
            stats refresh 10s
            stats auth admin:admin_pass
    
    sudo systemctl restart haproxy
    sudo systemctl status haproxy
## Проверка отказоустойчивости:
### Failover - переключение прошло успешно:
    nick@orlov:~$ vm_ip_address=$(yc compute instance show --name pgsql1 | grep -E ' +address' | tail -n 1 | awk '{print $2}') && ssh -o StrictHostKeyChecking=no -i ~/.ssh/id_ed25519 yc-user@$vm_ip_address
    Welcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.4.0-200-generic x86_64)
    
     * Documentation:  https://help.ubuntu.com
       * Management:     https://landscape.canonical.com
       * Support:        https://ubuntu.com/pro
    New release '22.04.5 LTS' available.
    Run 'do-release-upgrade' to upgrade to it.
    
    Last login: Fri Dec  6 05:14:43 2024 from 31.131.200.226
    yc-user@pgsql1:~$ 
    yc-user@pgsql1:~$ 
    yc-user@pgsql1:~$ sudo patronictl -c /etc/patroni.yml list
    + Cluster: patroni (7445162979816317630) --+----+-----------+
    | Member | Host      | Role    | State     | TL | Lag in MB |
    +--------+-----------+---------+-----------+----+-----------+
    | pgsql1 | 10.0.0.15 | Leader  | running   |  1 |           |
    | pgsql2 | 10.0.0.22 | Replica | streaming |  1 |         0 |
    | pgsql3 | 10.0.0.38 | Replica | streaming |  1 |         0 |
    +--------+-----------+---------+-----------+----+-----------+
    yc-user@pgsql1:~$ sudo systemctl stop patroni
    yc-user@pgsql1:~$ sudo patronictl -c /etc/patroni.yml list
      + Cluster: patroni (7445162979816317630) --+----+-----------+
      | Member | Host      | Role    | State     | TL | Lag in MB |
      +--------+-----------+---------+-----------+----+-----------+
      | pgsql1 | 10.0.0.15 | Replica | stopped   |    |   unknown |
      | pgsql2 | 10.0.0.22 | Replica | streaming |  2 |         0 |
      | pgsql3 | 10.0.0.38 | Leader  | running   |  2 |           |
      +--------+-----------+---------+-----------+----+-----------+
### Switchover  - переключение прошло успешно:
    yc-user@pgsql1:~$ patronictl -c /etc/patroni.yml switchover patroni
    Current cluster topology
    + Cluster: patroni (7445162979816317630) --+----+-----------+
    | Member | Host      | Role    | State     | TL | Lag in MB |
    +--------+-----------+---------+-----------+----+-----------+
    | pgsql1 | 10.0.0.15 | Replica | streaming |  2 |         0 |
    | pgsql2 | 10.0.0.22 | Replica | streaming |  2 |         0 |
    | pgsql3 | 10.0.0.38 | Leader  | running   |  2 |           |
    +--------+-----------+---------+-----------+----+-----------+
    Primary [pgsql3]: 
    Candidate ['pgsql1', 'pgsql2'] []: pgsql1    
    When should the switchover take place (e.g. 2024-12-06T06:29 )  [now]: 
    Are you sure you want to switchover cluster patroni, demoting current leader pgsql3? [y/N]: Y
    2024-12-06 05:29:07.88075 Successfully switched over to "pgsql1"
      + Cluster: patroni (7445162979816317630) --+----+-----------+
      | Member | Host      | Role    | State     | TL | Lag in MB |
      +--------+-----------+---------+-----------+----+-----------+
      | pgsql1 | 10.0.0.15 | Leader  | running   |  2 |           |
      | pgsql2 | 10.0.0.22 | Replica | streaming |  2 |         0 |
      | pgsql3 | 10.0.0.38 | Replica | stopped   |    |   unknown |
      +--------+-----------+---------+-----------+----+-----------+

    yc-user@pgsql1:~$ sudo patronictl -c /etc/patroni.yml list
    + Cluster: patroni (7445162979816317630) --+----+-----------+
    | Member | Host      | Role    | State     | TL | Lag in MB |
    +--------+-----------+---------+-----------+----+-----------+
    | pgsql1 | 10.0.0.15 | Leader  | running   |  3 |           |
    | pgsql2 | 10.0.0.22 | Replica | streaming |  3 |         0 |
    | pgsql3 | 10.0.0.38 | Replica | streaming |  3 |         0 |
    +--------+-----------+---------+-----------+----+-----------+

## Проверка соединения с БД:
### Нода лидер - можем писать:
    yc-user@pgsql1:~$ psql -h 10.0.0.38 -p 5432 -U postgres
    Password for user postgres: 
    psql (14.15 (Ubuntu 14.15-1.pgdg20.04+1))
    Type "help" for help.
    postgres=# create table test (id int);
    CREATE TABLE
    postgres=# insert into test(id) values (1);
    INSERT 0 1
### Нода реплика - ридонли:
    yc-user@pgsql1:~$ psql -h 10.0.0.22 -p 5432 -U postgres
    Password for user postgres: 
    psql (14.15 (Ubuntu 14.15-1.pgdg20.04+1))
    Type "help" for help.
    
    postgres=# insert into test(id) values (2);
    ERROR:  cannot execute INSERT in a read-only transaction
